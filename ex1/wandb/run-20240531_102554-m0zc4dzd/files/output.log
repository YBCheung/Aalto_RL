Environment: Reacher-v1
Training device: cuda
Observation space dimensions: 2
Action space dimensions: 5
Episode 0 finished. Total reward: -466.37571095414313 (200 timesteps)
Episode 1 finished. Total reward: -565.3174356646657 (200 timesteps)
Episode 2 finished. Total reward: -372.2214438488682 (200 timesteps)
Episode 3 finished. Total reward: -295.2644877843078 (157 timesteps)
Episode 4 finished. Total reward: -610.976664156996 (200 timesteps)
Episode 5 finished. Total reward: -590.6104942679058 (200 timesteps)
Episode 6 finished. Total reward: -589.9189657170759 (200 timesteps)
Episode 7 finished. Total reward: -439.6010602955984 (200 timesteps)
Episode 8 finished. Total reward: -270.6901885702641 (200 timesteps)
Episode 9 finished. Total reward: -412.7575294070674 (200 timesteps)
Updating the policy...
Error executing job with overrides: ['env=reacher_v1', 'train_episodes=500']
Traceback (most recent call last):
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/train.py", line 146, in main
    train_info = train(agent, env,
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/train.py", line 49, in train
    agent.update_policy()
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/agent.py", line 79, in update_policy
    self.ppo_epoch()
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/agent.py", line 110, in ppo_epoch
    returns = self.compute_returns()
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/agent.py", line 94, in compute_returns
    _, values = self.policy(self.states)
  File "/home/yibo/anaconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yibo/anaconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yibo/Robot/Reinforcement_learning/RL/rl_course/ex1/agent.py", line 30, in forward
    x_a = self.fc1_a(x)
  File "/home/yibo/anaconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yibo/anaconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yibo/anaconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.